{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyDhi5AevQSX",
        "outputId": "94dff0f6-8850-4746-c3a3-c333733471a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = fetch_openml(\"mnist_784\")\n",
        "\n",
        "mnist_df = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
        "\n",
        "# Extract the data and target (labels)\n",
        "data = mnist.data\n",
        "target = mnist.target.astype(int)\n",
        "\n",
        "# Define the dimensions of the grid\n",
        "grid_width = 10\n",
        "grid_height = 10\n",
        "\n",
        "# Create a subplot with the specified grid dimensions\n",
        "fig, axes = plt.subplots(grid_height, grid_width, figsize=(10, 10))\n",
        "\n",
        "# Loop through and display the images\n",
        "for i in range(grid_height):\n",
        "    for j in range(grid_width):\n",
        "        # Calculate the index for the current image in the grid\n",
        "        index = i * grid_width + j\n",
        "\n",
        "        # Get the image data and label for the current index\n",
        "        image_data = data.iloc[index].to_numpy().reshape(28, 28)\n",
        "        label = target[index]\n",
        "\n",
        "        # Plot the image on the current subplot\n",
        "        axes[i, j].imshow(image_data, cmap='gray')\n",
        "        axes[i, j].axis('off')  # Turn off axis labels\n",
        "        axes[i, j].set_title(f\"Label: {label}\")\n",
        "\n",
        "# Adjust spacing and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Apply PCA with 4 components\n",
        "n_components = 4\n",
        "pca = PCA(n_components=n_components)\n",
        "data_pca = pca.fit_transform(data)\n",
        "\n",
        "# Create a DataFrame for the PCA-transformed data\n",
        "pca_df = pd.DataFrame(data_pca, columns=[f'PC{i+1}' for i in range(n_components)])\n",
        "\n",
        "# Concatenate the PCA data with the target labels\n",
        "pca_df['target'] = target\n",
        "\n",
        "# pairplot for the PCA-transformed data\n",
        "sns.pairplot(pca_df, hue='target')\n",
        "plt.show()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_pca, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Gaussian Naive Bayes classification\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training and test data\n",
        "train_predictions = gnb.predict(X_train)\n",
        "test_predictions = gnb.predict(X_test)\n",
        "\n",
        "# Calculate and report accuracy for the training and test datasets\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"Accuracy on Training Dataset (PCA): {train_accuracy:.2f}\")\n",
        "print(f\"Accuracy on Test Dataset (PCA): {test_accuracy:.2f}\")\n",
        "\n",
        "# Apply PCA with 2 components\n",
        "n_components_2 = 2\n",
        "pca2 = PCA(n_components=n_components_2)\n",
        "data_pca_2 = pca2.fit_transform(data)\n",
        "\n",
        "# Create a DataFrame for the PCA-transformed data\n",
        "pca_2_df = pd.DataFrame(data_pca_2, columns=[f'PC{i+1}' for i in range(n_components_2)])\n",
        "\n",
        "# Concatenate the PCA data with the target labels\n",
        "pca_2_df['target'] = target\n",
        "\n",
        "# 4.1. Create a pairplot for the PCA-transformed data\n",
        "sns.pairplot(pca_2_df, hue='target')\n",
        "plt.show()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_pca_2, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4.2. Perform Gaussian Naive Bayes classification\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training and test data\n",
        "train_predictions = gnb.predict(X_train)\n",
        "test_predictions = gnb.predict(X_test)\n",
        "\n",
        "# Calculate and report accuracy for the training and test datasets\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"Accuracy on Training Dataset (PCA 2 Components): {train_accuracy:.2f}\")\n",
        "print(f\"Accuracy on Test Dataset (PCA 2 Components): {test_accuracy:.2f}\")\n",
        "\n",
        "# Apply Isomap to the PCA-transformed data\n",
        "isomap = Isomap(n_components=2)\n",
        "data_isomap = isomap.fit_transform(data_pca_2)\n",
        "\n",
        "# Create a DataFrame for the Isomap-transformed data\n",
        "isomap_df = pd.DataFrame(data_isomap, columns=['Component 1', 'Component 2'])\n",
        "\n",
        "# pairplot for the Isomap-transformed data\n",
        "sns.pairplot(isomap_df, hue=target)\n",
        "plt.title('Pair Plot for Isomap (PCA 2 Components)')\n",
        "plt.show()\n",
        "\n",
        "# Split the data into training and testing sets for Isomap\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_isomap, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Gaussian Naive Bayes classification on Isomap-transformed data\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the training and test data for Isomap\n",
        "train_predictions = gnb.predict(X_train)\n",
        "test_predictions = gnb.predict(X_test)\n",
        "\n",
        "# Calculate and report accuracy for Isomap-transformed data\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"Accuracy on Training Dataset (Isomap): {train_accuracy:.2f}\")\n",
        "print(f\"Accuracy on Test Dataset (Isomap): {test_accuracy:.2f}\")\n"
      ]
    }
  ]
}